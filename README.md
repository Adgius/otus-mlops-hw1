[Домашнее задание 1](#домашнее-задание-1)

[Домашнее задание 2](#домашнее-задание-2)

[Домашнее задание 3](#домашнее-задание-3)

# Домашнее задание 1

Цель проекта - разработать за полгода конкурентоспособную антифрод-систему.  Основная часть системы должна размещаться на внешних ресурсах. Система должна выдерживать высокие нагрузки. Также необходимо обеспечить конфиденциальность данных. За первые три месяца предоставить MVP.

Так как было определено, что у конкурентов максимум 2% мошеннических транзакций приводят к потере средств, то будем использовать метрику *False Negative Rate*:
$$FNR = \frac{FN}{FN+TP} * 100\% $$, где *FN* - число мошеннических транзакций, приведших к потере средств; *TP* - число распознаных мошеннических транзакций моделью. Данная метрика должна быть меньше 2%.

Для контроля недовольства клиентов – *False Positive Rate*. Доля ложных блокировок транзакций честного пользователя от общего числа транзакций.


$$FPR = \frac{FP}{FP+TN} * 100\%$$, где *FP* - число ложных срабатываний; *TN* - число обычных транзакций, которые распознаны как **не**мошеннические. Данная метрика должна быть меньше 5%.

Бизнес-метрика -- ущерб от мошеннических транзакций за месяц. Не должна превышать 500 тыс. рублей.

Особенности предстоящего проекта:

![image](https://github.com/Adgius/otus-mlops-hw1/assets/78685114/98e9fb05-7232-4f7a-a554-68f40fd44e61)

Основные фунциональные задачи:
1. Подготовка и сбор данных
2. Создание хранилища для данных
3. Разработка модели
4. Тесты
5. Деплой модели
6. Поддержка

# Домашнее задание 2

Основные команды:

**Создание бакета**

`yc storage bucket create --name otus-mlops-hw2 --default-storage-class cold --max-size 161061273600 --public-read --public-list`

Ссылка на s3: 

*s3://otus-mlops-hw2/fraud-data/*

**Копирование файлов с бакета на бакет**

`s3cmd cp -r --acl-public s3://mlops-data/fraud-data s3://otus-mlops-hw2/`

**Перемещение на hdfs**

`hadoop distcp s3a://otus-mlops-hw2/fraud-data/ /user/ubuntu/input/`

![image](https://github.com/Adgius/otus-mlops-hw1/assets/78685114/dfda7f39-5964-4100-b3ba-fb485d93ab6c)

Для поддержания работоспособности текущего сервиса (s3 + hdfs) необходимо ~26500 рублей
- S3 (150ГБ, холодное): ~250 руб/мес
- HDFS (мастер нода с публичным ip + дата нода 3 хоста) ~26000 руб/мес


В качестве оптимизации можно уменьшить число хостов в датаноде и использовать более дешевые конфигурации железа.

# Домашнее задание 3

**Создание бакета под очищенные данные**

`yc storage bucket create --name otus-mlops-data-clear --default-storage-class cold --max-size 161061273600 --public-read --public-list`

**Подключаемся к мастер ноде и запускаем jupyter notebook**

Чтобы в дальнейшем к нему подключиться, необходимо при создании кластера разрешить подключение на 8888 порт.

`jupyter notebook --no-browse --port 8888 --ip=*`

**Устанавливаем библиотеку для автоматического поиска зависимостей для Spark**

`pip install findspark`

**Исследуем данные**
[Ссылка на ноутбук](https://github.com/Adgius/otus-mlops-hw1/blob/master/3/data-exploration.ipynb)

**Составляем финальный скрипт**
[Ссылка на скрипт](https://github.com/Adgius/otus-mlops-hw1/blob/master/3/clean-data.py)

**Запускаем финальный скрипт для очистки**

В качестве аргументов передаем ключи от сервисного аккаунта s3.
`python clean-data.py [Идентификатор ключа] [Cекретный ключ]`
