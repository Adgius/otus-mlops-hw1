[Домашнее задание 1](#домашнее-задание-1)

[Домашнее задание 2](#домашнее-задание-2)

[Домашнее задание 3](#домашнее-задание-3)

[Домашнее задание 4](#домашнее-задание-4)

# Домашнее задание 1

Цель проекта - разработать за полгода конкурентоспособную антифрод-систему.  Основная часть системы должна размещаться на внешних ресурсах. Система должна выдерживать высокие нагрузки. Также необходимо обеспечить конфиденциальность данных. За первые три месяца предоставить MVP.

Так как было определено, что у конкурентов максимум 2% мошеннических транзакций приводят к потере средств, то будем использовать метрику *False Negative Rate*:
$$FNR = \frac{FN}{FN+TP} * 100\% $$, где *FN* - число мошеннических транзакций, приведших к потере средств; *TP* - число распознаных мошеннических транзакций моделью. Данная метрика должна быть меньше 2%.

Для контроля недовольства клиентов – *False Positive Rate*. Доля ложных блокировок транзакций честного пользователя от общего числа транзакций.


$$FPR = \frac{FP}{FP+TN} * 100\%$$, где *FP* - число ложных срабатываний; *TN* - число обычных транзакций, которые распознаны как **не**мошеннические. Данная метрика должна быть меньше 5%.

Бизнес-метрика -- ущерб от мошеннических транзакций за месяц. Не должна превышать 500 тыс. рублей.

Особенности предстоящего проекта:

![image](https://github.com/Adgius/otus-mlops-hw1/assets/78685114/98e9fb05-7232-4f7a-a554-68f40fd44e61)

Основные фунциональные задачи:
1. Подготовка и сбор данных
2. Создание хранилища для данных
3. Разработка модели
4. Тесты
5. Деплой модели
6. Поддержка

# Домашнее задание 2

Основные команды:

**Создание бакета**

`yc storage bucket create --name otus-mlops-hw2 --default-storage-class cold --max-size 161061273600 --public-read --public-list`

Ссылка на s3: 

*s3://otus-mlops-hw2/fraud-data/*

**Копирование файлов с бакета на бакет**

`s3cmd cp -r --acl-public s3://mlops-data/fraud-data s3://otus-mlops-hw2/`

**Перемещение на hdfs**

`hadoop distcp s3a://otus-mlops-hw2/fraud-data/ /user/ubuntu/input/`

![image](https://github.com/Adgius/otus-mlops-hw1/assets/78685114/dfda7f39-5964-4100-b3ba-fb485d93ab6c)

Для поддержания работоспособности текущего сервиса (s3 + hdfs) необходимо ~26500 рублей
- S3 (150ГБ, холодное): ~250 руб/мес
- HDFS (мастер нода с публичным ip + дата нода 3 хоста) ~26000 руб/мес


В качестве оптимизации можно уменьшить число хостов в датаноде и использовать более дешевые конфигурации железа.

# Домашнее задание 3

**Создание бакета под очищенные данные**

`yc storage bucket create --name otus-mlops-data-clear --default-storage-class cold --max-size 161061273600 --public-read --public-list`

**Подключаемся к мастер ноде и запускаем jupyter notebook**

Чтобы в дальнейшем к нему подключиться, необходимо при создании кластера разрешить подключение на 8888 порт.

`jupyter notebook --no-browse --port 8888 --ip=*`

**Устанавливаем библиотеку для автоматического поиска зависимостей для Spark**

`pip install findspark`

**Исследуем данные**
[Ссылка на ноутбук](https://github.com/Adgius/otus-mlops-hw1/blob/master/3/data-exploration.ipynb)

**Составляем финальный скрипт**
[Ссылка на скрипт](https://github.com/Adgius/otus-mlops-hw1/blob/master/3/clean-data.py)

**Запускаем финальный скрипт для очистки**

В качестве аргументов передаем ключи от сервисного аккаунта s3.
`python clean-data.py [Идентификатор ключа] [Cекретный ключ]`

# Домашнее задание 4

### Периодический запуск процедуры очистки датасета мошеннических финансовых транзакций

**Для начала создаем ВМ, где будет развернут Ariflow. Рекомендуется минимум 8 ГБ оперативной памяти** 

**Подключаемся к ВМ по ssh**

**Клонируем этот репозиторий на ВМ**

`git clone https://github.com/Adgius/otus-mlops-hw1.git`

**Перемещаемся в папку с текущим дз**

`cd otus-mlops-hw1/4/`

**Устанавливаем docker на ВМ, с помощью подготовленного скрипта**

`bash install-docker.sh`

Чтобы изменения вступили в силу перезаходим в терминал

**Для подключения к Spark кластеру будет необходим ssh-ключ, поэтому создаем его**

`ssh-keygen`

**Чтобы ключ работал в Airflow, перемещаем его в рабочий проект**

`cp -R $HOME/.ssh $HOME/otus-mlops-hw1/4/`

**В директории с дз необходимо создать файл с окружением, в который поместим идентификатор пользователя**

`echo -e "AIRFLOW_UID=$(id -u)" > $HOME/otus-mlops-hw1/4/.env`

**Запустим инициализацию базы данных и создание пользователя**

Команды надо выполнять в директории `$HOME/otus-mlops-hw1/4`

`docker compose up airflow-init`

**Запустим Airflow**

`docker compose up -d`

Подключиться к интерфейсу можно через ip ВМ и порта 8080. Пароль и логин: `airflow`

При входе мы увидим такую картину:
![image](https://github.com/Adgius/otus-mlops-hw1/assets/78685114/f1fc824f-0647-45dd-b045-a548d9121940)

Один даг не добавился по причине отсутствия адреса Spark кластера, потому что он еще не создан. Подлкючение автоматически появится после успешного завершения первого дага
