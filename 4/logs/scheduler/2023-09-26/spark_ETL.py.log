[2023-09-26T05:21:32.056+0000] {processor.py:157} INFO - Started process (PID=35) to work on /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:21:32.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark_ETL.py for tasks to queue
[2023-09-26T05:21:32.098+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:21:32.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:21:32.918+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:21:32.915+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark_ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_ETL.py", line 171, in <module>
    ssh_hook=create_ssh_hook(),
  File "/opt/airflow/dags/spark_ETL.py", line 135, in create_ssh_hook
    ssh_hook = SSHHook(ssh_conn_id='cluster_ssh_connection')
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/ssh/hooks/ssh.py", line 151, in __init__
    conn = self.get_connection(self.ssh_conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 72, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 477, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `cluster_ssh_connection` isn't defined
[2023-09-26T05:21:32.918+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:21:32.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark_ETL.py took 0.922 seconds
[2023-09-26T05:22:03.111+0000] {processor.py:157} INFO - Started process (PID=43) to work on /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:22:03.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark_ETL.py for tasks to queue
[2023-09-26T05:22:03.138+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:22:03.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:22:03.296+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:22:03.293+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark_ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_ETL.py", line 171, in <module>
    ssh_hook=create_ssh_hook(),
  File "/opt/airflow/dags/spark_ETL.py", line 135, in create_ssh_hook
    ssh_hook = SSHHook(ssh_conn_id='cluster_ssh_connection')
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/ssh/hooks/ssh.py", line 151, in __init__
    conn = self.get_connection(self.ssh_conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 72, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 477, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `cluster_ssh_connection` isn't defined
[2023-09-26T05:22:03.297+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:22:03.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark_ETL.py took 0.212 seconds
[2023-09-26T05:22:33.447+0000] {processor.py:157} INFO - Started process (PID=51) to work on /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:22:33.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark_ETL.py for tasks to queue
[2023-09-26T05:22:33.451+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:22:33.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:22:33.556+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:22:33.554+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark_ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_ETL.py", line 171, in <module>
    ssh_hook=create_ssh_hook(),
  File "/opt/airflow/dags/spark_ETL.py", line 135, in create_ssh_hook
    ssh_hook = SSHHook(ssh_conn_id='cluster_ssh_connection')
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/ssh/hooks/ssh.py", line 151, in __init__
    conn = self.get_connection(self.ssh_conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 72, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 477, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `cluster_ssh_connection` isn't defined
[2023-09-26T05:22:33.556+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:22:33.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark_ETL.py took 0.129 seconds
[2023-09-26T05:23:03.689+0000] {processor.py:157} INFO - Started process (PID=59) to work on /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:23:03.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark_ETL.py for tasks to queue
[2023-09-26T05:23:03.692+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:23:03.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:23:03.782+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:23:03.780+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark_ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_ETL.py", line 171, in <module>
    ssh_hook=create_ssh_hook(),
  File "/opt/airflow/dags/spark_ETL.py", line 135, in create_ssh_hook
    ssh_hook = SSHHook(ssh_conn_id='cluster_ssh_connection')
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/ssh/hooks/ssh.py", line 151, in __init__
    conn = self.get_connection(self.ssh_conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 72, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 477, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `cluster_ssh_connection` isn't defined
[2023-09-26T05:23:03.782+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:23:03.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark_ETL.py took 0.107 seconds
[2023-09-26T05:23:33.820+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:23:33.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark_ETL.py for tasks to queue
[2023-09-26T05:23:33.823+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:23:33.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:23:33.911+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:23:33.909+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark_ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_ETL.py", line 171, in <module>
    ssh_hook=create_ssh_hook(),
  File "/opt/airflow/dags/spark_ETL.py", line 135, in create_ssh_hook
    ssh_hook = SSHHook(ssh_conn_id='cluster_ssh_connection')
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/ssh/hooks/ssh.py", line 151, in __init__
    conn = self.get_connection(self.ssh_conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 72, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 477, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `cluster_ssh_connection` isn't defined
[2023-09-26T05:23:33.911+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:23:33.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark_ETL.py took 0.104 seconds
[2023-09-26T05:24:04.044+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:24:04.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark_ETL.py for tasks to queue
[2023-09-26T05:24:04.048+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:24:04.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:24:04.136+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:24:04.135+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark_ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_ETL.py", line 171, in <module>
    ssh_hook=create_ssh_hook(),
  File "/opt/airflow/dags/spark_ETL.py", line 135, in create_ssh_hook
    ssh_hook = SSHHook(ssh_conn_id='cluster_ssh_connection')
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/ssh/hooks/ssh.py", line 151, in __init__
    conn = self.get_connection(self.ssh_conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 72, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 477, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `cluster_ssh_connection` isn't defined
[2023-09-26T05:24:04.137+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:24:04.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark_ETL.py took 0.108 seconds
[2023-09-26T05:24:34.185+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:24:34.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark_ETL.py for tasks to queue
[2023-09-26T05:24:34.188+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:24:34.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:24:34.282+0000] {logging_mixin.py:151} INFO - [2023-09-26T05:24:34.279+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/spark_ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_ETL.py", line 171, in <module>
    ssh_hook=create_ssh_hook(),
  File "/opt/airflow/dags/spark_ETL.py", line 135, in create_ssh_hook
    ssh_hook = SSHHook(ssh_conn_id='cluster_ssh_connection')
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/ssh/hooks/ssh.py", line 151, in __init__
    conn = self.get_connection(self.ssh_conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 72, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 477, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `cluster_ssh_connection` isn't defined
[2023-09-26T05:24:34.282+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_ETL.py
[2023-09-26T05:24:34.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark_ETL.py took 0.113 seconds
